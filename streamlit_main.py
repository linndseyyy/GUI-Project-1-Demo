import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
import pickle
import streamlit as st
import matplotlib.pyplot as plt
from sklearn import metrics
import seaborn as sns
from product_search_service import search_product_by_code, print_product_info

# 1. Read data
# [Ben] change to utf-8 for vietnamese text
data = pd.read_csv("final_data3.csv", encoding='utf-8')
# 2. Data pre-processing
source = data['noi_dung_binh_luan']
target = data['label']

# [Ben] Clean NaN values by replacing them with empty string
source = source.fillna('')

text_data = np.array(source)

count = CountVectorizer(max_features=6000)
count.fit(text_data)
bag_of_words = count.transform(text_data)

X = bag_of_words.toarray()

y = np.array(target)

#3. Save models
  
# luu model CountVectorizer (count)
pkl_count = "count_model.pkl"  
with open(pkl_count, 'wb') as file:  
    pickle.dump(count, file)

#4. Load models 
# ƒê·ªçc model
# import pickle
pkl_filename = "lg_predictor.pkl"  
with open(pkl_filename, 'rb') as file:  
    lg_prediction = pickle.load(file)
# Read count len model
with open(pkl_count, 'rb') as file:  
    count_model = pickle.load(file)

#--------------
# GUI
st.title("Sentiment Analysis Project")
st.write("## Hasaki - ƒê√°nh gi√° t√≠ch c·ª±c v√† ti√™u c·ª±c")

menu = ["Business Objective", "Build Project", "New Prediction", "Product Search"]
choice = st.sidebar.selectbox('Menu', menu)
st.sidebar.write("""#### Th√†nh vi√™n th·ª±c hi·ªán:
                 L√™ Gia Linh & Ph·∫°m T∆∞·ªùng H√¢n""")
st.sidebar.write("""#### Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n: Khu·∫•t Thu·ª≥ Ph∆∞∆°ng""")
st.sidebar.write("""#### Th·ªùi gian th·ª±c hi·ªán: 12/2024""")
if choice == 'Business Objective':  
    st.subheader("Gi·ªõi thi·ªáu doanh nghi·ªáp")  
    st.write("""Hasaki.vn - m·ªôt h·ªá th·ªëng c·ª≠a h√†ng m·ªπ ph·∫©m ch√≠nh h√£ng v√† d·ªãch v·ª• chƒÉm s√≥c s·∫Øc ƒë·∫πp chuy√™n s√¢u v·ªõi m·∫°ng l∆∞·ªõi r·ªông kh·∫Øp Vi·ªát Nam. V·ªõi m·ªôt h·ªá th·ªëng website cho ph√©p kh√°ch h√†ng ƒë·∫∑t h√†ng v√† ƒë·ªÉ l·∫°i b√¨nh lu·∫≠n, Hasaki.vn c√≥ ƒë∆∞·ª£c m·ªôt c∆° s·ªü d·ªØ li·ªáu kh√°ch h√†ng l·ªõn v√† ƒë·∫ßy ti·ªÅm nƒÉng khai th√°c.
    """)  
    st.write(""" Gi·ªõi h·∫°n hi·ªán t·∫°i: D·ªØ li·ªáu ƒë√°nh gi√° l√† vƒÉn b·∫£n th√¥ v√† ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω m·ªôt c√°ch t·ª± ƒë·ªông ‚áí Y√™u c·∫ßu qu√° tr√¨nh ph√¢n t√≠ch th·ªß c√¥ng, t·ªën th·ªùi gian v√† d·ªÖ x·∫£y ra sai s√≥t.
    """)  
    st.image("Hasaki.jpg")
    st.subheader("Business Objective")
    st.write("""
    ###### X√¢y d·ª±ng h·ªá th·ªëng/m√¥ h√¨nh d·ª± ƒëo√°n nh·∫±m: 
            1. Ph√¢n lo·∫°i c·∫£m x√∫c c·ªßa kh√°ch h√†ng d·ª±a tr√™n c√°c ƒë√°nh gi√° (Positive, Neutral, Negative).
        2. TƒÉng t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c trong vi·ªác ph·∫£n h·ªìi √Ω ki·∫øn c·ªßa kh√°ch h√†ng.
        3. H·ªó tr·ª£ Hasaki.vn v√† c√°c ƒë·ªëi t√°c c·∫£i thi·ªán s·∫£n ph·∫©m, d·ªãch v·ª•, n√¢ng cao s·ª± h√†i l√≤ng c·ªßa kh√°ch h√†ng.
    """)  
    st.write("""###### Y√™u c·∫ßu: D√πng thu·∫≠t to√°n Machine Learning algorithms trong Python ƒë·ªÉ ph√¢n lo·∫°i b√¨nh lu·∫≠n t√≠ch c·ª±c, trung t√≠nh v√† ti√™u c·ª±c.""")
    st.image("Sentiment Analysis.jpg")

elif choice == 'Build Project':
    st.subheader("Build Project")
    st.write("##### 1. M·ªôt v√†i d·ªØ li·ªáu")
    st.dataframe(data[['ma_san_pham','noi_dung_binh_luan', 'label']].head(3))
    st.dataframe(data[['ma_san_pham','noi_dung_binh_luan', 'label']].tail(3))  

    st.write("##### 2. Tr·ª±c quan ho√° Sentiment Analysis")
    st.write("###### Wordcloud b√¨nh lu·∫≠n")
    st.image("Wordcloud.png")
    st.write("###### Ki·ªÉm tra s·ª± c√¢n b·∫±ng d·ªØ li·ªáu")
    st.image("Plot 1.png")
    st.write("""###### ‚áí D·ªØ li·ªáu kh√¥ng c√¢n b·∫±ng, c·∫ßn th·ª±c hi·ªán oversample ƒë·ªÉ c√¢n b·∫±ng d·ªØ li·ªáu""")
    st.write("""###### Sau khi th·ª±c hi·ªán c√¢n b·∫±ng d·ªØ li·ªáu""")
    st.image("Plot 2.png")
   
    st.write("##### 3. X√¢y d·ª±ng m√¥ h√¨nh")
    st.write("""X√¢y d·ª±ng m·ªôt m√¥ h√¨nh s·ª≠ d·ª•ng ƒëa d·∫°ng c√°c thu·∫≠t to√°n g·ªìm Naive Bayes, Logistic Regression v√† Random Forest. C√°c m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n c√°c ƒë√°nh gi√° c·ªßa kh√°ch h√†ng v·ªÅ s·∫£n ph·∫©m tr√™n website Hasaki.vn ƒë·ªÉ ph√¢n lo·∫°i th√†nh c√°c m·ª©c ƒë·ªô c·∫£m x√∫c.""")

    st.write("##### 4. ƒê√°nh gi√°")
    st.write("""X√¢y d·ª±ng m·ªôt m√¥ h√¨nh s·ª≠ d·ª•ng ƒëa d·∫°ng c√°c thu·∫≠t to√°n g·ªìm Naive Bayes, Logistic Regression v√† Random Forest. C√°c m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n c√°c ƒë√°nh gi√° c·ªßa kh√°ch h√†ng v·ªÅ s·∫£n ph·∫©m tr√™n website Hasaki.vn ƒë·ªÉ ph√¢n lo·∫°i th√†nh c√°c m·ª©c ƒë·ªô c·∫£m x√∫c.""")
    st.write("""###### ƒê·ªô ch√≠nh x√°c v√† th·ªùi gian ch·∫°y model""")
    st.image("Model Performance.png") 
    st.write("""###### Confusion Matrix""")
    st.write("""Naive Bayes""")
    st.image("Confusion Matrix for Naive Bayes.png")
    st.write("""Logistic Regression""")
    st.image("Confusion Matrix for Logistic Regression.png")
    st.write("""Random Forest""")
    st.image("Confusion Matrix for Random Forest.png")
    st.write("##### 5.K·∫øt lu·∫≠n: M√¥ h√¨nh Logistic Regression ph√π h·ª£p nh·∫•t ƒë·ªëi v·ªõi Sentiment Analysis c·ªßa t·∫≠p d·ªØ li·ªáu c·ªßa Hasaki.vn.")
    st.write("#### M√¥ h√¨nh Logistic Regression ph√π h·ª£p nh·∫•t ƒë·ªëi v·ªõi Sentiment Analysis c·ªßa t·∫≠p d·ªØ li·ªáu c·ªßa Hasaki.vn.")

elif choice == 'New Prediction':
    st.subheader("Select data")
    flag = False
    lines = None
    type = st.radio("Upload data or Input data?", options=("Upload", "Input"))
    if type=="Upload":
        # Upload file
        uploaded_file_1 = st.file_uploader("Choose a file", type=['txt', 'csv'])
        if uploaded_file_1 is not None:
            lines = pd.read_csv(uploaded_file_1, header=None)
            st.dataframe(lines)            
            lines = lines[0]     
            flag = True                          
    if type=="Input":        
        content = st.text_area(label="Input your content:")
        if content!="":
            lines = np.array([content])
            flag = True
    
    if flag:
        st.write("Content:")
        if len(lines)>0:
            st.code(lines)        
            x_new = count_model.transform(lines)        
            y_pred_new = lg_prediction.predict(x_new)       
            st.code("New predictions (0: Negative, 1. Neutral, 2: Positive): " + str(y_pred_new))

# Added product search functionality
elif choice == 'Product Search':
    st.subheader("Product Search")
    
    product_code = st.text_input("Enter Product Code:")
    
    if st.button("Search"):
        if product_code:            
            product_info = search_product_by_code(product_code)
            print_product_info(product_info)

            if product_info:
                st.title(f"üì¶ {product_info['ten_san_pham']}")

                # Product info in a nice box
                st.info(f"üì¶ {product_info['mo_ta']}")
                
                # Rating with stars
                rating = float(product_info['avg_so_sao'])
                st.markdown(f"### ‚≠ê Rating: {rating:.1f}/5.0")

                left_col, right_col = st.columns(2)

                # Left column: Pie Chart
                with right_col:
                    fig, ax = plt.subplots(figsize=(6, 4))
                    reviews = [int(product_info['total_positive']), int(product_info['total_negative'])]
                    labels = ['Positive', 'Negative']
                    colors = ['#2ecc71', '#e74c3c']
                    ax.pie(reviews, labels=labels, autopct='%1.1f%%', colors=colors)
                    plt.title('Review Distribution')
                    st.pyplot(fig)

                # Right column: Review Statistics
                with left_col:
                    with st.expander("üìä Review Statistics", expanded=True):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Positive Reviews", product_info['total_positive'], "üëç", delta_color="normal")
                        with col2:
                            st.metric("Negative Reviews", product_info['total_negative'], "üëé", delta_color="inverse")


                # Most used words
                with st.expander("üìù Most Used Words", expanded=True):
                    st.metric("Positive Keyword", product_info['most_popular_positive_word'], "‚ú®", delta_color="normal")
                    st.metric("Negative Keyword", product_info['most_popular_negative_word'], "‚ö†Ô∏è", delta_color="inverse")
                  
            else:
                st.error("Product not found!")
        else:
            st.warning("Please enter a product code")




